%==============================================================================
% Voorstel-inhoud — enkel de hoofdtekst (géén \documentclass, géén \begin{document})
%==============================================================================

% TODO (feedback): Is dit voorstel gebaseerd op een paper van Research Methods die je
% vorig jaar hebt ingediend? Heb je daarbij eventueel samengewerkt met een andere student?
% - Zo ja, haal dan de tekst hieronder uit commentaar en pas aan.
% - Zo nee, verwijder dit hele blok.

% \paragraph{Opmerking}
% Dit voorstel is gebaseerd op het onderzoeksvoorstel dat werd geschreven in het
% kader van het vak Research Methods dat ik (vorig/dit) academiejaar heb
% uitgewerkt (met medestudent VOORNAAM NAAM als mede-auteur).

%---------- Inleiding ---------------------------------------------------------

\section{Inleiding}
\label{sec:inleiding}

De Belgische huurmarkt is sterk verschoven naar online platformen: het grootste deel van het beschikbare aanbod wordt daar gepubliceerd. Voor kandidaat huurders is het zoekproces bovendien tijdsgevoelig. Huurpanden die aansluiten bij het budget en de locatievoorkeuren verdwijnen vaak snel uit het online aanbod, waardoor regelmatig zoeken een voordeel oplevert. Tegelijk is het aanbod versnipperd. Dezelfde woning verschijnt niet zelden op meerdere platformen, elk met eigen filters, presentatie en meldingsmechanismen.

Veel platformen bieden zoekmeldingen of e-mailalerts, maar die zijn platformgebonden en laten vaak beperkte controle toe over criteria, transparantie en meldingskwaliteit. In de praktijk combineren kandidaat huurders daarom meerdere websites: ze voeren dezelfde zoekopdracht opnieuw uit, houden verschillende alerts actief en vergelijken resultaten manueel. Dat kost tijd en zorgt voor meldingsruis. Dubbele meldingen ontstaan wanneer één woning op meerdere platformen wordt aangeboden, irrelevante meldingen ontstaan wanneer filters te grof zijn of wanneer platformen dezelfde voorkeuren niet op dezelfde manier ondersteunen.

Deze bachelorproef onderzoekt binnen die context welke ontwerpkeuzes in een centraal, platform onafhankelijk zoek en alertmechanisme het meest bijdragen aan het verminderen van dubbele en irrelevante meldingen. Het gaat daarbij niet om het afleveren van een product, maar om het vergelijken van ontwerpkeuzes voor normalisatie, matching/filtering en deduplicatie over meerdere bronnen heen.

Om die ontwerpkeuzes systematisch te kunnen analyseren, wordt een beperkte proof of concept gebruikt als onderzoeksinstrument. In deze demonstrator worden meerdere varianten van matching en deduplicatiestrategieën toegepast op huurdata afkomstig van minstens twee Belgische huurplatformen. De evaluatie gebeurt aan de hand van meetbare criteria (onder meer aandeel duplicaten, false positives en gemiste relevante panden) en wordt aangevuld met feedback van testgebruikers over ervaren relevantie.

Om het onderzoek haalbaar en afgebakend te houden, wordt de scope beperkt tot:
\begin{enumerate}
  \item huurpanden (geen koopmarkt);
  \item een beperkte selectie van grote Belgische huurplatformen (minstens twee bronnen binnen haalbare technische en juridische randvoorwaarden);
  \item een representatieve maar beperkte set zoekcriteria (bijvoorbeeld prijs, regio, type woning en aantal slaapkamers);
  \item een technische demonstrator die uitsluitend dient ter ondersteuning van het onderzoek en niet als productierijp systeem.
\end{enumerate}


%---------- Probleemstelling, onderzoeksvraag en doelstellingen ----------------
\sloppy
\section{Probleemstelling, onderzoeksvraag en doelstellingen}
\label{sec:onderzoeksvraag}

\subsection*{Probleemstelling}

Voor kandidaat huurders in België is het zoeken naar een geschikt huurpand sterk verspreid over meerdere online vastgoedplatformen. Wie snel wil reageren op nieuw aanbod, raadpleegt daardoor vaak meerdere websites en herhaalt dat proces regelmatig. In een markt waar geschikte panden snel verdwijnen, maakt die versnippering het zoeken tijdrovend en onoverzichtelijk.

Veel platforms bieden zoekmeldingen of e-mailalerts, maar die werken enkel binnen één platform en hebben vaak beperkte of weinig fijnmazige filtermogelijkheden. Wanneer kandidaat huurders verschillende platformen combineren, ontstaan twee concrete problemen. Ten eerste komen dubbele meldingen vaak voor omdat dezelfde woning op meerdere platformen wordt gepubliceerd. Ten tweede leiden beperkte filters tot irrelevante meldingen: meldingen die niet (of slechts gedeeltelijk) aansluiten bij de zoekvoorkeuren van de gebruiker. Het gevolg is meldingsmoeheid en minder overzicht, waardoor belangrijke meldingen net gemist kunnen worden.

Een centraal platform onafhankelijk zoek en alertmechanisme kan deze problemen in principe verminderen, maar het is vandaag onduidelijk welke ontwerpkeuzes daarvoor het meest doeltreffend zijn. In het bijzonder ontbreekt inzicht in de impact van verschillende aanpakken voor (1) normalisatie van data uit meerdere bronnen, (2) matching en filtering, en (3) deduplicatie over platformen heen. Dit onderzoek richt zich daarom op het vergelijken van die ontwerpkeuzes en het empirisch aantonen van hun effect op dubbele en irrelevante meldingen.

\subsection*{Onderzoeksvraag}

\begin{quote}
Welke ontwerpkeuzes in een centraal platform onafhankelijk zoek en alertmechanisme voor de Belgische huurmarkt verminderen dubbele en irrelevante meldingen het meest, zonder dat relevante opportuniteiten onnodig verloren gaan?
\end{quote}

\subsection*{Deelvragen -- probleemdomein}

\begin{enumerate}
  \item Welke vastgoedplatformen zijn relevant voor kandidaat huurders in België, en welke beperkingen vertonen de huidige platformgebonden zoek en alertmechanismen op vlak van filtering, meldingskwaliteit en overlap tussen platformen?
  \item Welke minimale set van data is nodig om een platform onafhankelijk zoek en filterprofiel toe te passen (bijvoorbeeld prijs, locatie, type woning, slaapkamers, oppervlakte, beschikbaarheid), en in welke mate is die informatie consistent en publiek beschikbaar op de geselecteerde platformen?
  \item Welke technische en juridische randvoorwaarden bepalen de haalbaarheid van geautomatiseerde monitoring van de geselecteerde platformen (bijvoorbeeld \texttt{robots.txt}, gebruiksvoorwaarden, databankrechten en privacy), en welke beperkingen leggen die randvoorwaarden op aan dataverzameling en hergebruik?
\end{enumerate}

\subsection*{Deelvragen -- oplossingsdomein}

\begin{enumerate}
  \setcounter{enumi}{3}
  \item Welke architectuur is het meest geschikt om een centraal zoek en alertmechanisme te realiseren (scheiding tussen dataverzameling, normalisatie, matching/deduplicatie en notificatie), en hoe beïnvloedt die architectuur de uitbreidbaarheid (nieuwe bron toevoegen) en onderhoudbaarheid (wijzigingen in bronstructuur)?
  \item Welke matching en filterstrategieën leveren de beste balans tussen het beperken van irrelevante meldingen en het vermijden van gemiste opportuniteiten (bijvoorbeeld strikt filteren versus scoring-gebaseerd), en welke parameters zijn daarbij bepalend?
  \item Welke deduplicatiestrategieën over meerdere bronnen heen verlagen het aandeel dubbele meldingen het sterkst met een aanvaardbaar risico op foutieve samenvoegingen (bijvoorbeeld exact match op adres versus combinatie van kenmerken zoals prijsband, locatie en woningkenmerken)?
  \item Welke evaluatiemethode en meetcriteria zijn geschikt om de impact van deze ontwerpkeuzes te vergelijken (bijvoorbeeld aandeel duplicaten, aantal false positives, aantal gemiste relevante panden, en gebruikersperceptie), en in welke mate stemmen de meetresultaten overeen met feedback van testgebruikers?
\end{enumerate}

\subsection*{Doelstellingen}

Dit onderzoek heeft als doel om:
\begin{enumerate}
  \item de knelpunten in het huidige zoekproces van kandidaat huurders in België te beschrijven, met focus op fragmentatie, tijdsdruk en meldingskwaliteit (dubbele en irrelevante meldingen)
  \item de relevante platformen en de minimaal noodzakelijke data te bepalen om zoekprofielen platform onafhankelijk te kunnen toepassen
  \item meerdere varianten van matching/filtering en deduplicatie te ontwerpen en systematisch te vergelijken binnen dezelfde context en dataset
  \item de impact van die varianten empirisch te evalueren aan de hand van meetbare criteria (onder anderen. duplicaten, false positives en gemiste relevante panden), aangevuld met gebruikersfeedback
  \item op basis van de resultaten onderbouwde conclusies en aanbevelingen te formuleren over doeltreffende ontwerpkeuzes en de beperkingen van een centraal, platform onafhankelijk zoek en alertmechanisme.
\end{enumerate}


%---------- Literatuurstudie ---------------------------------------------------
\sloppy
\section{Literatuurstudie}
\label{sec:literatuurstudie}

Deze literatuurstudie ondersteunt de probleemstelling en onderzoeksvraag uit Sectie~\ref{sec:onderzoeksvraag}. Ze bundelt de inzichten die nodig zijn om ontwerpkeuzes voor een centraal, platform onafhankelijk zoek en alertmechanisme objectief te vergelijken op hun impact op meldingskwaliteit. De synthese focust op vier thema’s: (1) waarom fragmentatie en tijdsdruk bij online woningzoeken leiden tot meldingsruis, (2) hoe listingdata uit meerdere vastgoedplatformen genormaliseerd kan worden tot een uniform schema, (3) welke matching en deduplicatiestrategieën gangbaar zijn en welke trade-offs ze veroorzaken, en (4) met welke meetcriteria het effect van die keuzes kan worden aangetoond (onder andere duplicaatratio, false positives en gemiste relevante panden), aangevuld met gebruikersperceptie.

\subsection*{Tijdsdruk en fragmentatie bij online woningzoeken}

Woningzoekgedrag is de voorbije jaren sterk online geworden. Studies tonen dat gebruikers vaak herhaaldelijk zoeken en filters gebruiken om snel een selectie te maken, en dat timing mee bepaalt welke aanbiedingen men effectief ziet \autocite{rae2015housingsearch}.
Voor België wordt ook met online listingdata gewerkt om zoekactiviteit en marktgedrag te analyseren \autocite{vandenbergh2024belgiumsearch}.
Dit ondersteunt het vertrekpunt van deze bachelorproef. In een gefragmenteerde sector stijgt de kans op overlap tussen resultaten en wordt het opvolgen van nieuw aanbod snel tijdrovend.

\subsection*{Meldingskwaliteit en meldingsruis}

Alerts zijn pas nuttig als meldingen relevant blijven. Onderzoek rond notificaties toont dat frequente of storende meldingen ertoe leiden dat gebruikers meldingen negeren of uitschakelen \autocite{ohly2023notifications}.
Voor deze bachelorproef is dat vooral belangrijk om twee begrippen in stand te houden:
\begin{enumerate}
  \item \textbf{dubbele meldingen}: dezelfde woning verschijnt meer dan één keer;
  \item \textbf{irrelevante meldingen}: meldingen die niet overeenkomen met het zoekprofiel (false positives).
\end{enumerate}
Omdat strengere filters ook relevante panden kunnen missen, is het zinvol om in de evaluatie ook gemiste relevante panden  (false negatives) mee te nemen.

\subsection*{Normalisatie en data-integratie over meerdere bronnen}

Wanneer data van meerdere platformen samenkomt, zijn velden en formaten zelden hetzelfde. In data integratie wordt dit doorgaans aangepakt door een beperkt intern schema te definiëren en brondata te normaliseren \autocite{rahm2001schemamatching}.
Voor vastgoeddata betekent kernvelden definiëren zoals prijs, locatie, type woning en aantallen (bijvoorbeeld\ slaapkamers), en het documenteren van normalisatieregels. Die stap is nodig om matching en deduplicatie eerlijk te kunnen vergelijken.

\subsection*{Matching en deduplicatie (entity resolution)}

Het herkennen van dezelfde woning over meerdere bronnen valt onder \emph{entity resolution} of record linkage \autocite{getoor2012er, christen2012datamatching}. Literatuur over duplicate detection bespreekt de belangrijkste onderdelen zoals gelijkenisfuncties, blocking en de trade-off tussen nauwkeurigheid en efficiëntie \autocite{elmagarmid2007duplicate}. Omdat vastgoeddata vaak ruis bevat (tekstvariaties, prijsaanpassingen, onvolledige adressen), worden in dit onderzoek twee types aanpakken vergeleken:
\begin{enumerate}
  \item \textbf{strikt}: exact match op sterke sleutels (bijvoorbeeld volledig adres) of strikte combinaties;
  \item \textbf{scoring-gebaseerd}: meerdere kenmerken samen, met een drempel om records als duplicaat te zien \autocite{fellegi1969recordlinkage}.
\end{enumerate}
Deze keuze beïnvloedt zowel het aantal overblijvende duplicaten als het risico op foutieve samenvoegingen.

\subsection*{Dataverzameling en randvoorwaarden}

Als er geen API beschikbaar is, kan scraping/crawling gebruikt worden. Maar dit brengt verschillende potentiële problemen met zich mee. Wijzigingen aan websites en de regels van crawling zijn realistische risico’s.
Daarnaast geeft het Robots Exclusion Protocol (robots.txt) richtlijnen die crawlers geacht worden te respecteren \autocite{rfc9309}.
Ten slotte bepalen juridische kaders mee wat haalbaar is: databankbescherming (EU Databankenrichtlijn) en privacywetgeving (GDPR) zijn relevante randvoorwaarden bij hergebruik en opslag \autocite{eu2016gdpr}.
In deze bachelorproef worden die randvoorwaarden gebruikt om de selectie van bronnen en de scope van de proof of concept af te bakenen.

\subsection*{Evaluatie: meetcriteria voor “beter”}

Omdat de onderzoeksvraag draait rond impact op dubbele en irrelevante meldingen, moet de evaluatie dat ook aantonen.
Voor het onderscheid tussen false positives en gemiste relevante items zijn precisie en recall standaardbegrippen uit information retrieval.
Voor deduplicatie/ER worden gelijkaardige criteria gebruikt (bijvoorbeeld\ duplicaatpercentage na clustering en fouten door over of onder samenvoegen) \autocite{christen2012datamatching}.
In dit onderzoek wordt daarom gemeten: (1) aandeel duplicaten, (2) false positives, (3) gemiste relevante panden, aangevuld met korte gebruikersfeedback over ervaren relevantie.

\subsection*{Synthese}

De literatuur ondersteunt dat woningzoeken tijdsgevoelig is en dat fragmentatie over platformen de kans op meldingsruis verhoogt \autocite{rae2015housingsearch}.
Technisch wijst de literatuur erop dat normalisatie en entity resolution geen “one size fits all” hebben: keuzes rond matching en deduplicatie veroorzaken duidelijke trade-offs \autocite{getoor2012er, elmagarmid2007duplicate}.
Daarom vergelijkt deze bachelorproef een beperkte set van varianten (strikt vs scoring-gebaseerd; simpel vs multi-feature deduplicatie) en evalueert ze die varianten met meetcriteria die zowel meldingsruis als gemiste opportuniteiten mee in beeld brengen.

%---------- Methodologie -------------------------------------------------------
\section{Voorgestelde methodologie}
\label{sec:methodologie}

Het doel van dit onderzoek is niet om een productierijp systeem te bouwen, maar om ontwerpkeuzes in een centraal platform onafhankelijk zoek en alertmechanisme te vergelijken.
Daarom wordt een beperkte proof of concept ontwikkeld als onderzoeksinstrument: dezelfde inputdata en dezelfde zoekprofielen worden herhaaldelijk verwerkt met verschillende varianten voor (1) matching en filtering en (2) deduplicatie.
De impact wordt beoordeeld met meetcriteria die zowel meldingsruis als gemiste relevante opportuniteiten zichtbaar maken.

\subsection*{Fase 1 -- Afbakening, bronnenkeuze en randvoorwaarden}

\textbf{Doel:} de onderzoekscontext vastleggen en een haalbare selectie van bronnen en zoekcriteria bepalen.

\begin{enumerate}
  \item Selecteren van minstens twee relevante Belgische huurplatformen die voldoende data aanbieden voor vergelijking.
  \item Vastleggen van een beperkte maar representatieve set zoekcriteria die op de gekozen platformen voldoende consistent voorkomt (bijvoorbeeld prijs, regio, type woning en aantal slaapkamers).
  \item Analyseren van technische en juridische randvoorwaarden per huurplatform
  \begin{enumerate}
    \item raadplegen van robots.txt en publieke gebruiksvoorwaarden
    \item inschatten van risico's rond aanpassingen aan het huurplatform (wijzigende structuur) 
  \end{enumerate}
\end{enumerate}



\textbf{Output:} een scopetabel met per gekozen huurplatform beschikbare velden, extractiehaalbaarheid, beperkingen/risico's, en een finale lijst van opgenomen zoekcriteria.

\subsection*{Fase 2 -- Dataverzameling en datasetconstructie}

\textbf{Doel:} een dataset opbouwen waarop varianten vergeleken kunnen worden.

\begin{enumerate}
\item Opzetten dataverzameling voor nieuwe listings binnen geselecteerde huurplatformen. Via API indien beschikbaar, anders via scraping.
  \item Opslaan van  listings in bronformaat (bron-URL en tijdstip van ophalen) zodat latere controle en reproduceerbaarheid mogelijk blijven.
  \item Samenstellen van datasets voor analyse en evaluatie:
  \begin{enumerate}
    \item een volledige ruwe dataset voor verwerking;
    \item een gelabelde subset voor evaluatie.
  \end{enumerate}
\end{enumerate}

\textbf{Output:} een dataset per huurplatform (ruwe listings) en een beschrijving van de verzamelperiode en het datavolume.

\subsection*{Fase 3 -- Normalisatie naar een uniform intern schema}

\textbf{Doel:} listings uit meerdere huurplatformen omzetten naar een gemeenschappelijk datamodel zodat matching en deduplicatie vergelijkbaar worden.

\begin{enumerate}
  \item Defini\"eren van een intern data schema met kernvelden (zoals prijs, locatie, type woning, aantal slaapkamers, bron-URL en publicatiemoment).
  \item Implementeren van bron specifieke mappers die velden omzetten naar het interne schema, inclusief normalisatieregels.
  \item Kwaliteitscontrole op de genormaliseerde data. Zoals ontbrekende waarden per veld en incositenties.
\end{enumerate}

\textbf{Output:} intern datamodel als schema ,mappingdocument per bron en een genormaliseerde dataset.
\subsection*{Fase 4 -- Variantspecificatie: matching/filtering en deduplicatie}

\textbf{Doel:} de varianten vastleggen die met elkaar vergeleken worden.

\begin{enumerate}
  \item \textbf{Zoekprofielen:}
  \begin{enumerate}
    \item opstellen van een beperkte set representatieve zoekprofielen op basis van interviews of vereisten.
    \item bepalen welke criteria strikt zijn (bijvoorbeeld maximumprijs, regio) en welke criteria flexibel mogen zijn.
  \end{enumerate}

  \item \textbf{Matching en filtering (2 varianten):}
  \begin{enumerate}
    \item M1 - strikt: enkel resultaten die aan alle criteria voldoen.
    \item M2 - score: resultaten krijgen een score. Enkel resultaten boven een vaste drempel worden behouden.
  \end{enumerate}

  \item \textbf{Deduplicatie (2 varianten):}
  \begin{enumerate}
    \item D1 -- \textit{regels:} dubbels herkennen via vaste combinaties van sterke kenmerken.
    \item D2 -- \textit{score:} dubbels herkennen via een gelijkenisscore met een vaste drempel.
  \end{enumerate}
\end{enumerate}

\textbf{Output:} een korte variantfiche met de gekozen regels/drempels en een proof of concept die alle varianten kan uitvoeren.

\subsection*{Fase 5 -- Evaluatie}

\textbf{Doel:} nagaan welke varianten zorgen voor minder dubbele en minder irrelevante meldingen, zonder te veel relevante panden te missen.
\begin{enumerate}
  \item \textbf{Gelabelde testset maken:}
  \begin{enumerate}
    \item voor een beperkte subset aanduiden welke listings hetzelfde pand zijn (duplicaten)
    \item voor dezelfde subset per zoekprofiel aanduiden of een listing relevant is (eventueel met korte feedback van testgebruikers).
  \end{enumerate}

  \item \textbf{Metingen per variantcombinatie (M en D):}
  \begin{enumerate}
    \item hoeveel dubbels blijven er over na deduplicatie.
    \item hoeveel irrelevante meldingen worden toch doorgelaten.
    \item hoeveel relevante panden worden gemist.
    \item hoeveel verschillende panden worden foutief samengevoegd.
  \end{enumerate}

  \item \textbf{Korte gebruikerstest (ondersteunend):}
  \begin{enumerate}
    \item enkele testgebruikers bekijken een beperkte set meldingen en geven korte feedback over relevantie en duidelijkheid;
    \item de feedback wordt kort samengevat en vergeleken met de meetresultaten.
  \end{enumerate}
\end{enumerate}

\textbf{Output:} tabellen/grafieken die de varianten vergelijken en een korte conclusie over de beste aanpak binnen de scope.

\subsection*{Fase 6 -- Reproduceerbaarheid en kwaliteitsbewaking}

\textbf{Doel:} zorgen dat resultaten controleerbaar en herhaalbaar zijn.

\begin{enumerate}
  \item Vastleggen van dataset snapshots en configuratiebestanden zodat runs herhaald kunnen worden.
  \item Logging van aantallen records per stap (ruw, genormaliseerd, na deduplicatie, matches per profiel) en van fouten.
  \item Rapporteren van beperkingen (zoals ontbrekende of inconsistente velden, en wijzigingen in bronstructuur) en hun mogelijke impact op de resultaten.
\end{enumerate}

\textbf{Output:} logbestanden, configuraties en een korte validiteits- en beperkingenparagraaf bij de resultaten.


%---------- Verwachte resultaten en bijdrage -----------------------------------

\sloppy
\section{Verwachte resultaten en bijdrage}
\label{sec:verwachte-resultaten}
De verwachte output van dit onderzoek is een duidelijke vergelijking van verschillende keuzes voor
(1) matching/filtering en (2) deduplicatie bij huur alerts over meerdere platformen.
Ik bouw een beperkte proof of concept om die keuzes op dezelfde data te testen en eerlijk te vergelijken.

De verwachte bijdrage bestaat uit:
\begin{enumerate}
  \item een korte afbakening van de gebruikte huurplatformen, de beschikbare velden en de belangrijkste beperkingen
  \item een eenvoudig, uniform datamodel met normalisatie zodat listings van verschillende platformen vergelijkbaar worden
  \item een beschrijving van de geteste varianten (matching en deduplicatie) met hun regels / drempels
  \item meetresultaten per variant zoals aantal duplicaten dat overblijft, aantal irrelevante meldingen, aantal gemiste relevante panden en aantal foutieve samenvoegingen
  \item een korte conclusie met aanbevelingen: welke aanpak werkt het best binnen de gekozen scope en waarom.
\end{enumerate}

%---------- Verwacht resultaat en conclusie -----------------------------------


\sloppy
\section{Verwacht resultaat en conclusie}
\label{sec:verwacht_resultaat_conclusie}

Er wordt verwacht dat meldingen vooral slechter worden door (1) duplicaten tussen platformen en
(2) filters die niet goed genoeg zijn door verschillen in data.
Het onderzoek moet aantonen welke combinatie van matching en deduplicatie het beste evenwicht geeft tussen
minder ``ruis'' en zo weinig mogelijk gemiste panden.

Concreet wordt verwacht dat:
\begin{enumerate}
  \item strikte matching minder irrelevante meldingen geeft maar sneller relevante panden mist
  \item scoring gebaseerde matching meer kans geeft om relevante panden te vinden maar soms extra ruis toelaat
  \item sterkere deduplicatie meer dubbele meldingen wegneemt maar het risico verhoogt op fout samenvoegen
  \item de beste aanpak diegene is met duidelijk minder duplicaten en ruis zonder veel relevante panden te missen
\end{enumerate}

De conclusie zal dus een onderbouwd antwoord geven op:
\begin{enumerate}
  \item welke ontwerpkeuzes het beste werken binnen de afgebakende scope
  \item waar de meeste fouten vandaan komen (data-verschillen, ontbrekende velden, drempels)
  \item wat je als volgende stap best verbetert (bijvoorbeeld betere normalisatie of extra kenmerken voor deduplicatie).
\end{enumerate}



\clearpage
\appendix

